{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gridWorld\n",
    "import graphics \n",
    "import time\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Create our grid\n",
    "length = 6\n",
    "width =  6\n",
    "\n",
    "goalX = length / 2\n",
    "goalY = width / 2\n",
    "\n",
    "currentX = 1\n",
    "currentY = 1\n",
    "\n",
    "# Create object to hold all the information associated with the grid\n",
    "# The code for this enviroment is in gridWorld.py (I wrote it)\n",
    "myGrid = gridWorld.grid(length, width, currentX, currentY, goalX, goalY)\n",
    "\n",
    "discount = 0.80\n",
    "learning_rate = 0.80\n",
    "\n",
    "numGames = 100000\n",
    "\n",
    "# Define the neural network structure\n",
    "Q_value = keras.Sequential([\n",
    "    keras.layers.Dense(30, input_dim = length * width ),\n",
    "    keras.layers.Dense(20),\n",
    "    keras.layers.Dense(10),\n",
    "    keras.layers.Dense(4)\n",
    "])\n",
    "\n",
    "\n",
    "# Set more of the model's parameters\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.0005)\n",
    "\n",
    "Q_value.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "\n",
    "# This defines how much data to generate before training\n",
    "batch_size = 40\n",
    "\n",
    "# These will hold the in/out data pairs\n",
    "training_labels = []\n",
    "input_data = []\n",
    "\n",
    "# This defines the explore rate\n",
    "epsilon = 0.5\n",
    "# This defines the rate at which epsilon (ie the explore rate) will decay\n",
    "epsilonDecay = 0.9\n",
    "\n",
    "# Prior state tracking\n",
    "currentY_p = currentY\n",
    "currentX_p = currentX\n",
    "\n",
    "for game_num in range(1, numGames):\n",
    "    \n",
    "    for i in range(20):\n",
    "        myGrid.render(Q_value)\n",
    "        \n",
    "        # Choose an action\n",
    "        # 0 - 4 is left, right, up, down\n",
    "        # argmax returns the index of the max element\n",
    "        action = np.argmax( Q_value.predict( myGrid.convertToInput(currentX, currentY) ) )\n",
    "            \n",
    "        # Explore or not?\n",
    "        if ( epsilon > random.random() ):\n",
    "            # Choose action randomnly\n",
    "            action = random.randrange(4)\n",
    "            \n",
    "        # Track the prior location\n",
    "        currentY_p = currentY\n",
    "        currentX_p = currentX\n",
    "\n",
    "        # Observe the reward and the next state\n",
    "        current_reward, isOver, currentX, currentY = myGrid.step(action)\n",
    "\n",
    "        # Record the \"label\" \n",
    "        label = Q_value.predict( myGrid.convertToInput(currentX, currentY) )\n",
    "        \n",
    "        # Compute the bellman equation\n",
    "        label[0][action] = current_reward + (discount * np.amax( Q_value.predict( myGrid.convertToInput(currentX, currentY) ) ) ) \n",
    "       \n",
    "        # Format the data for Tensorflow\n",
    "        label = np.array( label[0] )\n",
    "        training_labels.append(label)\n",
    "\n",
    "        # This is the input data\n",
    "        input_data.append(  myGrid.convertToInput(currentX_p, currentY_p)[0] )\n",
    "        \n",
    "        if ( isOver == True ):\n",
    "            myGrid.reset()\n",
    "            break\n",
    "    \n",
    "    # Do a training epoch \n",
    "    if (game_num % batch_size == 0):\n",
    "        \n",
    "        # Format the data for Tensorflow\n",
    "        input_data = np.array(input_data)\n",
    "        training_labels = np.array(training_labels)\n",
    "       \n",
    "        # Update the Q-Table\n",
    "        Q_value.fit(input_data, training_labels, epochs = 12)\n",
    "\n",
    "        # Traverse the grid and redraw the arrows\n",
    "        for i in range(myGrid.length):\n",
    "            for j in range (myGrid.width):\n",
    "            \n",
    "                # 0 - 4 is left, right, up, down\n",
    "                action = Q_value.predict( myGrid.convertToInput(j, i) ) \n",
    "\n",
    "                action = np.argmax(action)\n",
    " \n",
    "                # Re-draw arrow  \n",
    "                myGrid.changeArrow(j, i, action)\n",
    "        \n",
    "        # Let the epsilon rate decay - i.e. explore less\n",
    "        epsilon = epsilon * epsilonDecay\n",
    "\n",
    "        training_labels = []\n",
    "        input_data = [] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
